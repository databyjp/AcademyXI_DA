{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GGif4c7Cyjx7",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/databyjp/AcademyXI_DA/blob/main/notebooks/AcademyXi_DA_Module_6_data_cleaning_workshop.ipynb)\n",
    "\n",
    "## AcademyXi Data Analysis - Data Manipulation\n",
    "### Workshop - Data cleaning with Python\n",
    "In this workshop module, we will use Python to perform data cleaning tasks.  \n",
    "\n",
    "Using Python makes it very easy to clean data in a consistent, repeatable manner, as well as to automate the process. This makes it possible to clean large quantities of data in a very short amount of time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ukhbsu7w8dB1",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Preparation\n",
    "\n",
    "This will prepare our notebook including installing required packages and loading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0mN67cEK8Uj2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Install additional libraries required (fsspec and s3fs) to load files through AWS S3\n",
    "%%capture tmp\n",
    "!pip install fsspec s3fs\n",
    "\n",
    "# Import libraries to be used\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OV22lhHk8hi9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load data from S3\n",
    "df = pd.read_csv(\"s3://databyjp/academyxi/wk6_missing_data_example_MajorPowerStations_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 531
    },
    "id": "ZZiDkD8G8jES",
    "outputId": "13dce2f6-2481-4ac4-b300-60df3b49bf9d",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Check that the file has been properly loaded\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uC7KDDoA-Vx2",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Identify missing values\n",
    "\n",
    "Pandas includes many powerful tools to inspect and clean your data. The `.info` method will show how many values are in each column, as well as the data type: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_V3BMiviWxAK",
    "outputId": "8ac00500-b069-404b-8730-a09e47533dd2",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vfk4PoAVW1Z7",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "And at a more granular level, pandas can include many functions to identify rows or cells with missing data.\n",
    "\n",
    "For example, the `.isna` method can be used to produce Boolean values indicating whether the data is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "VgVg2NTR_r5V",
    "outputId": "d6fc4a71-7d42-4158-fa45-34f48a3c9cab",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[[\"GENERATORNUMBER\"]].isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rs-HxLtHAdOg",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The resulting series of Boolean values can be used to filter the entire dataframe. For example, the below filters the dataframe to only show rows containing missing values in the `\"PRIMARYSUBFUELTYPE\"` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "eB6NNDey_xEp",
    "outputId": "1900866f-ecf7-409b-dd54-d5db24f1ecf3",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[df[\"PRIMARYSUBFUELTYPE\"].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "royfa_bxNce6",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This can be used to assign the resulting clean(er) dataframes to a new variable.\n",
    "\n",
    "For example, we can invert the selection, or use the `notna` method to exclude rows with missing data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8vHoAcURNTZ1",
    "outputId": "12d3ba2b-16e4-46d0-d81e-d807525de0ba",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_a = df[-df[\"GENERATORNUMBER\"].isna()]\n",
    "df_b = df[df[\"GENERATORNUMBER\"].notna()]\n",
    "df_a.equals(df_b)  # Method to check if two dataframes are identical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VTQC6OYvaE-p",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MDs_bPiJR8gb",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To drop rows or columns containing **any** missing data, Pandas' `dropna` method can be used. Note that this results in a much smaller dataframe compared to the original dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "U5fqaO2gSQgM",
    "outputId": "0e57b61d-a5b9-4781-afc2-0155d4d67abc",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hDmBtkwsKCVN",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Cleaing erroneous text\n",
    "\n",
    "We learned earlier about different data types such as strings (text) and integers (whole numbers). A mixture of data types can be a more problematic in programming languages more than in Excel, which often silently and dynamically converts data types.\n",
    "\n",
    "Take a look below, where we use the `.unique` method to show all unique values in the `GENERATORNUMBER` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eecG4knsKHyi",
    "outputId": "714e90e8-263c-4f94-f0c8-6ca2d03e9f6b",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[\"GENERATORNUMBER\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TN6BZQyfQjPo",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It includes a `nan` value (for not a number). The quotation marks around values indicate that the numbers are actually saved as strings. This is due to the last value, where the text `<Null>` has somehow found its way into the dataset. \n",
    "\n",
    "Let's clean up these values, replacing `<Null>` with an actuall null value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aAaxxfr3RDXt",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[\"GENERATORNUMBER\"] = df[\"GENERATORNUMBER\"].replace(\"<Null>\", np.nan)\n",
    "df[\"GENERATORNUMBER\"] = df[\"GENERATORNUMBER\"].replace(np.nan, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYOfYp0wRl2O",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now, we can change the data type to an interger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oAy8m5CTRjUN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[\"GENERATORNUMBER\"] = df[\"GENERATORNUMBER\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i6QVdES9Rywt",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "And now, if we view the unique values, we see the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nx9urVr5RxfH",
    "outputId": "b5bf3b4a-e886-4551-d7d7-c8ecbb606687",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[\"GENERATORNUMBER\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EdoBAkQASAPW",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can inspect the data type also:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A_C3v1kxR7uC",
    "outputId": "ea97a016-bcd3-4cd9-cc60-def1df063d73",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "type(df[\"GENERATORNUMBER\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oyXkzr-cPQ0O",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Imputing values\n",
    "\n",
    "Pandas provides multiple default methods with which missing data may be filled ([Documentation on filling missing values](https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html#filling-missing-values-fillna)).\n",
    "\n",
    "One method is to simply fill the missing cells with a scalar value, such as a median:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fDKmvjawO40i",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[\"GENERATORNUMBER\"] = df[\"GENERATORNUMBER\"].fillna(df[\"GENERATORNUMBER\"].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EneW8wVySJ_T",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Note that a median value is only able to be calculated for a column of numbers. If we had not cleaned the `GENERATORNUMBER` column by removing the `\"<Null>\"` text value and converted the column to a set of integers, this median value would not have been possible to determine.\n",
    "\n",
    "Another way of filling data is to forward/backward fill data `fillna(method='ffill')` or `fillna(method='bfill')`, where the last non-blank value forward or backward of the blank value is used. These may be appropriate where a value is missing in the middle of a series of data, such as stock prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FbL6V3FYcN_b",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Standarding categorical variables\n",
    "\n",
    "Using pandas' `unique` method, we can sort the list of categorical variables like so, which will show a number of very similar items:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KOdoV2kUJ6D1",
    "outputId": "14b4e566-c525-4b9c-c595-755c185ecfcf",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[\"GENERATIONTYPE\"] = df[\"GENERATIONTYPE\"].fillna(\"UNKNOWN\")\n",
    "for i in np.sort(df[\"GENERATIONTYPE\"].unique()):\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDB1ebTssGR6",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We see the `\"<Null>\"` value again, so let's clean it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BHhRZoHHsNB3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[\"GENERATIONTYPE\"] = df[\"GENERATIONTYPE\"].replace(\"<Null>\", \"UNKNOWN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hc6krNYqgSF4",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can take one of a few different approaches to programmatically clean this column and group these items together. \n",
    "\n",
    "One is to manually do so, by using a common string which is used by all common column values. The following code will simplify:\n",
    "- Cogeneration\n",
    "- Cogeneration - Spark Ignition Reciprocat\n",
    "- Cogeneration - Steam Subcritical\n",
    "All to \"Cogeneration\" in a new column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pzOVawPrfpxi",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = df.assign(simple_gen_type=\"UNKNOWN\")  # Create a new column, assign value \"UNKNOWN\" to all as default\n",
    "df.loc[\n",
    "       df[\"GENERATIONTYPE\"].str.contains(\"Cogeneration\"), \"simple_gen_type\"\n",
    "] = \"Cogeneration\"  # Where the \"GENERATIONTYPE\" column contains the string \"Cogeneration\", assign \"Cogeneration\" to the \"simple_gen_type\" column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F9JyR6-Qi1zS",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Taking a look at just the `GENERATIONTYPE` and `simple_gen_type` columns, we see that one values covers all of these types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "mYYL-tOViFQA",
    "outputId": "7a6bc90c-65f6-453e-d29f-baeec2c08c79",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[df[\"simple_gen_type\"] == \"Cogeneration\"][[\"GENERATIONTYPE\", \"simple_gen_type\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I99ae9WjjTrl",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The same can be done with strings such as \"Hydroelectric\", and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HzyXTc5FiwcG",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[\n",
    "       df[\"GENERATIONTYPE\"].str.contains(\"Hydroelectric\"), \"simple_gen_type\"\n",
    "] = \"Hydroelectric\"  # Where the \"GENERATIONTYPE\" column contains the string \"Hydroelectric\", assign \"Hydroelectric\" to the \"simple_gen_type\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "-SVwgBkJjLD2",
    "outputId": "cc410d9c-0d78-49cf-dc01-f5d74ef3e7a3",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[(df[\"simple_gen_type\"] == \"Cogeneration\") | (df[\"simple_gen_type\"] == \"Hydroelectric\")][[\"GENERATIONTYPE\", \"simple_gen_type\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZyJv3rcqshuX",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Other approaches to this will involves some form of langugage processing, which in itself is quite complex. Some simple methods might include:\n",
    "- Grabbing the first \"word\" (i.e. characters before a space), \n",
    "- Grabbing the firt n characters, or\n",
    "\n",
    "Here are quick demonstrations of each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PRIHKgpSjPrN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = df.assign(gentype_firstword=df[\"GENERATIONTYPE\"].apply(lambda x: x.split(\" \")[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "XB4z8lb4tJUb",
    "outputId": "86b17a57-58f0-4965-8e8b-0fc5c7000a22",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[[\"GENERATIONTYPE\", \"gentype_firstword\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y3r-UyGKtMPs",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = df.assign(gentype_firstfive=df[\"GENERATIONTYPE\"].str[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "lQjw6t7rtSIX",
    "outputId": "59fcac7f-f0f2-4e7d-d768-1d00220f8910",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[[\"GENERATIONTYPE\", \"gentype_firstfive\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Other methods might include grouping unique texts by their similarity 'distance' to each other. This begins to become quite complex both in terms of the natural langugage processing definition of how to measure similarity as well as python implementation, so we will not get into it here.\n",
    "\n",
    "-----\n",
    "\n",
    "But this may help you to get started:\n",
    "\n",
    "https://stackoverflow.com/questions/67240893/how-to-group-data-frame-with-similar-text-in-python\n",
    "\n",
    "And an explanation of Levenshtein distance can be found here:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Levenshtein_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "As you know by now, data cleaning can involve many different types of tasks, including some which can may be potentially very time-consuming. Using a programming language such as R or Python can help to automate them or even tackle tasks which may be otherwise impossible."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AcademyXi_DA_Module_6_data_cleaning_workshop.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
