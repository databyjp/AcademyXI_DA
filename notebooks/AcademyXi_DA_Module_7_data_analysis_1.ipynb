{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "AcademyXi_DA_Module_7_data_analysis_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/databyjp/AcademyXI_DA/blob/main/notebooks/AcademyXi_DA_Module_7_data_analysis_1.ipynb)\n",
    "\n",
    "## AcademyXi Data Analysis - Data Analysis 1: \n",
    "### Workshop - Data analysis with Python\n",
    "In this workshop module, we will show you how to use Python to perform some the data analysis tasks you've already seen."
   ],
   "metadata": {
    "id": "Al6GGTdB9RKT"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Install additional libraries required (fsspec and s3fs) to load files through AWS S3\n",
    "%%capture tmp\n",
    "!pip install fsspec s3fs\n",
    "\n",
    "# Import libraries to be used\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px"
   ],
   "metadata": {
    "id": "q0WNwxh0DbUD"
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Visualising distributions\n",
    "\n",
    "Below reproduces many of the charts from earlier in the module with Plotly. Although you have already seen how to produce statistical visualisations such as histograms, these may be useful as revision material."
   ],
   "metadata": {
    "id": "hqUuhFfLDQDg"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "mdlrDUEW9NiZ"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"s3://databyjp/academyxi/wk7_physPerformance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "id": "DgetAY9bEY9m",
    "outputId": "454fe502-a958-4378-dc45-25d805602f0c",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Histogram - see https://plotly.com/python/histograms/\n",
    "fig = px.histogram(df, x=\"height_cm\", nbins=40)\n",
    "fig.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "lYaVUBGKEaYZ",
    "outputId": "07780308-31a1-4a32-e1f9-5e4289f61766",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "fig = px.histogram(df, x=\"gripForce\", nbins=40)\n",
    "fig.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "OzMxlP_QFNAD",
    "outputId": "3e873445-30bd-4106-c522-615bc8b3bc48",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "fig = px.histogram(df, x=\"gripForce\", nbins=40, color=\"gender\")\n",
    "fig.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "y15SAwuAFYxj",
    "outputId": "9b84d108-b412-4ca8-c26c-27c08282264f",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Overlaid histogram - https://plotly.com/python/histograms/#overlaid-histogram\n",
    "fig = px.histogram(df, x=\"gripForce\", nbins=40, color=\"gender\")\n",
    "fig.update_layout(barmode='overlay')  \n",
    "fig.update_traces(opacity=0.75)\n",
    "fig.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "vrkUYP5SFeM0",
    "outputId": "d4b87eb3-aa62-464d-e770-3de8a9862fe8",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "fig = px.scatter(df, x=\"weight_kg\", y=\"height_cm\")\n",
    "fig.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "sqP2NrLSGVCU",
    "outputId": "23135243-ed4a-40cc-9f41-492e445ba9cc",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "fig = px.scatter(df, x=\"weight_kg\", y=\"broad jump_cm\")\n",
    "fig.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7dOpTb-UGoFn",
    "outputId": "17883c28-028c-4613-9cca-7def92a26ff2",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "fig = px.scatter(df, x=\"weight_kg\", y=\"broad jump_cm\", color=\"gender\")\n",
    "fig.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bMj507q7GvJG",
    "outputId": "06175ffa-436c-42cb-bdaa-6fd99b5d0606",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Scatter plot matrices (aka Pairplots)\n",
    "\n",
    "Now that you know how to use scatter plots to identify correlations, you may wish to start visualising a number of combinations of variables. \n",
    "\n",
    "This task is made easier with tools which can produce scatter plot matrics, also known as pairplots.\n",
    "\n",
    "- https://plotly.com/python/splom/\n",
    "- https://seaborn.pydata.org/generated/seaborn.pairplot.html\n",
    "\n",
    "See an example below"
   ],
   "metadata": {
    "id": "sueAx6p9HYRn"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "fig = px.scatter_matrix(df,\n",
    "                        dimensions=[\"age\", \"height_cm\", \"diastolic\", \"gripForce\", \"broad jump_cm\"], \n",
    "                        color=\"gender\")\n",
    "fig.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yO3unNsfG0up",
    "outputId": "4d5c6278-9b0d-42e4-c6d9-661ab2aae988",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Although crude due to resolution limitations, these plots give some idea of correlation between variables at a glance, which may help to narrow down your search.\n",
    "\n",
    "In almost all visualisation tools, you can adjust marker sizes. Where there are too many overlapping markers, plotting a randomly sampled subset may also help to reveal global patterns."
   ],
   "metadata": {
    "id": "YbTjdg9aJgZR"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "sm_df = df.sample(frac=0.05)  # Create a dataframe with only a small portion of the full size dataframe\n",
    "fig = px.scatter_matrix(sm_df,\n",
    "                        dimensions=[\"age\", \"height_cm\", \"diastolic\", \"gripForce\", \"broad jump_cm\"], \n",
    "                        color=\"gender\")\n",
    "fig.update_traces(marker=dict(size=2))  # Set a small size for the markers to better see patterns\n",
    "fig.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IopHbV_3HWgU",
    "outputId": "4c125a67-7c09-44ef-e984-5efb0ea8218c",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Grouping data\n",
    "\n",
    "In pandas, grouping data is a two-step process comprising of using the `groupby` method to create a grouped data object, and then using one or more aggregation functions such as:\n",
    "- `count`\n",
    "- `sum`\n",
    "- `min`\n",
    "- `max`\n",
    "\n",
    "To generate summaries of the grouped data. The resulting outputs are similar to what is possible through pivot tables."
   ],
   "metadata": {
    "id": "ZkV3y95NiTMy"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's now open the Melbourne housing dataset which you would have seen before:"
   ],
   "metadata": {
    "id": "2yM8A_QMAcHg"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"s3://databyjp/academyxi/wk7_melbourne_housing.csv\")"
   ],
   "metadata": {
    "id": "RMN_kjTJJ2SD"
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "j6ncNvFrlEr0",
    "outputId": "7f807dee-b26a-49f1-f3ca-d40af363e80c",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "We see in our casual inspection that the `Price` column includes null values. Let's clean the data by dropping those rows."
   ],
   "metadata": {
    "id": "TZbMhFnFA-S2"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df = df[df[\"Price\"].notna()]"
   ],
   "metadata": {
    "id": "JwSW0TE2ldi1"
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, we can find which suburb's listings have the most or fewest rooms on average. This can be done by:\n",
    "- Grouping the data by `Suburb` column, and\n",
    "- Taking the mean of the values"
   ],
   "metadata": {
    "id": "Kr3NuxM5BeHu"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "grp_df = df.groupby(\"Suburb\")  # Group the dataframe\n",
    "mean_rms = grp_df.mean()[\"Rooms\"]  # Take a mean\n",
    "print(mean_rms.sort_values().round(2))  # Sort by values, round to 2 decimal places, then print to screen"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZM8cwlnTlF6C",
    "outputId": "f7079cfb-f32a-47e5-9c7f-a9db54546349",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now see if you can do the same, but get the mean prices, grouped by number of rooms"
   ],
   "metadata": {
    "id": "2VPAJkHtM-6o"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# How would you modify the below to group the data by rooms, and print mean prices?\n",
    "# Note: .astype(int) converts the resulting data to integers\n",
    "print(df.groupby(\"Suburb\").mean()[\"Rooms\"].sort_values().astype(int))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xxeYKH1tlPzw",
    "outputId": "d6a8e457-d002-4a2a-a87b-9eb3ab08e43f",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "To group the data by multiple columns, the input should be a python list as shown below. This will produce a grouped pandas series with a nested index (multi-index)."
   ],
   "metadata": {
    "id": "xYyySIYgO0BO"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "tmp_ser = df.groupby([\"Bedroom2\", \"Bathroom\"]).mean()[\"Price\"].astype(int)"
   ],
   "metadata": {
    "id": "c9_HsCEPlQZn"
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tmp_ser.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HKy49vZFPa6F",
    "outputId": "d63e0bc3-4db0-4a5c-fea1-22111cbb5f8e",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "The series can be converted a dataframe by the `.reset_index` method:"
   ],
   "metadata": {
    "id": "ekerOpKDPU4y"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "grp_df = tmp_ser.reset_index()\n",
    "grp_df.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "31-No08BlpvD",
    "outputId": "40075c05-0793-42a0-d83b-95a13183d1ac",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "It can be filtered just as we had previously done."
   ],
   "metadata": {
    "id": "aPRYcxliP1LZ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "grp_df = grp_df[(grp_df[\"Bathroom\"] > 0) & (grp_df[\"Bedroom2\"] <= 3)]"
   ],
   "metadata": {
    "id": "WrhPjzaVmjFu"
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "grp_df"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "9gS4PGXUmjxi",
    "outputId": "26abdf74-d66d-479b-8711-6a381a8f5f7a",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Data bins\n",
    "\n",
    "Bins of data can be created by pandas' `cut` or `qcut` methods to convert continuous variables to discrete ones. `cut` will create bins of given sizes, whereas `qcut` will create  bins based on number of observations in each bin.\n",
    "\n",
    "Documentation:\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.cut.html\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.qcut.html"
   ],
   "metadata": {
    "id": "mWgFzO2gQABJ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "cut_bins = [i for i in range(0, 51, 5)]  # Create bins (0 to 50 in steps of 5) \n",
    "dist_bins = pd.cut(df[\"Distance\"], bins=cut_bins)\n",
    "df = df.assign(dist_bins=dist_bins)"
   ],
   "metadata": {
    "id": "R0gTBHYenEF5"
   },
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df.groupby(\"dist_bins\").mean()[\"Price\"].astype(int)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d706_7L8n1WS",
    "outputId": "4ae4e572-3e34-4eff-86ae-11605bb1850b",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Multiple aggregations\n",
    "\n",
    "For aggregate multiple columns, pandas provides the `agg` method which allows aggregating different columns as well as different methods within. \n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.agg.html"
   ],
   "metadata": {
    "id": "wday-JwQVFgo"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df.groupby(\"dist_bins\").agg({\"Price\": \"mean\", \"Suburb\": \"count\"}).astype(int)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "XH8Wmo5IpEe_",
    "outputId": "ad12ab4a-8431-4726-817a-98daea52387a",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Combining tables\n",
    "\n",
    "Pandas provides functionalities to allow multiple tables to be joined. The main method with which to do this is its `merge` method. \n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html\n",
    "\n",
    "Take a look at the below examples:"
   ],
   "metadata": {
    "id": "UT-XDTPz3HI_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "pop_df = pd.read_csv(\"s3://databyjp/academyxi/wk7_wdi_pop_simple.csv\")\n",
    "co2_df = pd.read_csv(\"s3://databyjp/academyxi/wk7_wdi_co2_simple.csv\")"
   ],
   "metadata": {
    "id": "JCx1uE2I36xs"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "pop_df.head()"
   ],
   "metadata": {
    "id": "4inqDE4r-wpt"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "co2_df.head()"
   ],
   "metadata": {
    "id": "8REWo87h-1rc"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "To create an inner join on the `Country Code` column, the following syntax can be used."
   ],
   "metadata": {
    "id": "PVQU6HxrWNf-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "merged_df = pop_df.merge(co2_df, how=\"inner\", on=\"Country Code\")"
   ],
   "metadata": {
    "id": "UZqcIVDd-dFR"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "merged_df.head()"
   ],
   "metadata": {
    "id": "K0LIbqdg-4tY"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, let's see what would happen with dataframes containing slightly different indices. This can be created in our case by dropping null data rows, as each dataset is missing data for different countries.\n",
    "\n",
    "Once the missing data has been dropped, we can see that the number of observations are different."
   ],
   "metadata": {
    "id": "UukiHIuFWeB_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "co2_df = co2_df[co2_df[\"CO2 emissions (kt)\"].notna()]\n",
    "pop_df = pop_df[pop_df[\"Population, total\"].notna()]\n",
    "print(f\"co2_df is {len(co2_df)} rows long\")\n",
    "print(f\"pop_df is {len(pop_df)} rows long\")"
   ],
   "metadata": {
    "id": "eMWR-wKa-96p"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, take a look at the differences produced by:\n",
    "- Inner join,\n",
    "- Left join,\n",
    "- Right join, and\n",
    "- Outer join"
   ],
   "metadata": {
    "id": "8ORzNCubW8_p"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "inner_merged_df = pop_df.merge(co2_df, how=\"inner\", on=\"Country Code\")"
   ],
   "metadata": {
    "id": "0qCAySww_Fbb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "inner_merged_df.head()"
   ],
   "metadata": {
    "id": "F9sw54Y2_HDW"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "left_merged_df = pop_df.merge(co2_df, how=\"left\", on=\"Country Code\")"
   ],
   "metadata": {
    "id": "6M55DJAp_HvV"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "left_merged_df.head()"
   ],
   "metadata": {
    "id": "wjBRlr-N_c97"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "right_merged_df = pop_df.merge(co2_df, how=\"right\", on=\"Country Code\")"
   ],
   "metadata": {
    "id": "Hvpv-Pnn_fCD"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "right_merged_df.head()"
   ],
   "metadata": {
    "id": "rQfn-ub9_kVx"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "outer_merged_df = pop_df.merge(co2_df, how=\"outer\", on=\"Country Code\")"
   ],
   "metadata": {
    "id": "R7xflMhI_lzt"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "outer_merged_df.head()"
   ],
   "metadata": {
    "id": "2No5QeQ9_onp"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can check the number of rows in each dataframe:"
   ],
   "metadata": {
    "id": "A-KBxBJ1XPPw"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"Inner merged dataframe: {len(inner_merged_df)} rows long\")\n",
    "print(f\"Left merged dataframe: {len(left_merged_df)} rows long\")\n",
    "print(f\"Right merged dataframe: {len(right_merged_df)} rows long\")\n",
    "print(f\"Outer merged dataframe: {len(outer_merged_df)} rows long\")"
   ],
   "metadata": {
    "id": "0Kak8l5N_p7n"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can see that inner join only includes rows which are present in both dataframes, while left/right join only includes rows of the respective dataframes. \n",
    "\n",
    "The outer join includes rows that are present in at least one of the two dataframes."
   ],
   "metadata": {
    "id": "-tV2nwSGXVWY"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "-----\n",
    "\n",
    "That's it for this tutorial. There's a lot more which you can do with Python in relation to exploratory data analysis as well as merging dataframes, but we hope this gave you an introduction. Feel free to adapt this notebook to different datasets, or search other Python modules and examples for EDA."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}