{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NbP4w48uCaPI",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/databyjp/AcademyXI_DA/blob/main/notebooks/AcademyXi_DA_Module_4_data_manip_workshop.ipynb)\n",
    "\n",
    "## AcademyXi Data Analysis - Data Manipulation\n",
    "### Workshop - Data manipulation in practice\n",
    "In this workshop module, we will go through a number of ways in which you can use Python for data manipulation. \n",
    "\n",
    "Think of this as a beginning of a rich, rewarding journey. We appreciate that some of the below may seem difficult (or easy) depending on your experience level with Python and Pandas. \n",
    "\n",
    "If you're not sure about how some part of the code below is working, try reviewing the documentation for the method or function (e.g. [here](https://pandas.pydata.org/docs/index.html)). Alternatively, think about what the code has done to the underlying data, and go back to the code to see if you can understand the steps it's taken to do so.\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSMlY-uk9lIJ"
   },
   "source": [
    "### Preparation\n",
    "\n",
    "This will prepare our notebook including installing required packages and loading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "cE172qkQCZOz"
   },
   "outputs": [],
   "source": [
    "# Install additional libraries required (fsspec and s3fs) to load files through AWS S3\n",
    "%%capture tmp\n",
    "!pip install fsspec s3fs\n",
    "\n",
    "# Import libraries to be used\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5G0JDH9INSCb"
   },
   "outputs": [],
   "source": [
    "# Load data from S3\n",
    "df = pd.read_csv(\"s3://databyjp/academyxi/Datafiniti_Womens_Shoes_sm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MjHnSR-rESCR"
   },
   "outputs": [],
   "source": [
    "# Check that the file has been properly loaded\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ld26xFzEecL"
   },
   "outputs": [],
   "source": [
    "# Show summary information about the DataFrame, as well as individual columns\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xVTwcYigWbXU"
   },
   "source": [
    "## Sort / filter data\n",
    "\n",
    "Sorting and filtering data in a Pandas DataFrame is easy and powerful. Take a look at some common ways to do it below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_nuAx0VQDrku"
   },
   "source": [
    "### Sort data with Python and Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CHr_w2Q0Az6l"
   },
   "outputs": [],
   "source": [
    "# We will be using just a few columns, so let's make a copy of the DataFrame with only those\n",
    "sdf = df[[\"id\", \"prices.merchant\", \"prices.amountMax\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BvEfsVJVXBZj"
   },
   "outputs": [],
   "source": [
    "# .sort_values method is one you will be using the most often. It can take one argument like so:\n",
    "sdf.sort_values(\"prices.amountMax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TiXGHKz4XbcM"
   },
   "outputs": [],
   "source": [
    "# Or provide multiple arguments as a list, which will then sort the data in the order of columns specified\n",
    "sdf.sort_values([\"prices.merchant\", \"prices.amountMax\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FnRS02mFBMpQ"
   },
   "outputs": [],
   "source": [
    "# By default, .sort_values method sorts the data in ascending order. \n",
    "# To sort in descending order, add the ascending=False argument.\n",
    "sdf.sort_values([\"prices.merchant\", \"prices.amountMax\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x3oLEk5eDNPb"
   },
   "outputs": [],
   "source": [
    "# To sort one column in ascending order and another in descending order, chain the methods\n",
    "# Note that when chaining the methods, the order of columns should be reversed\n",
    "sdf.sort_values(\"prices.amountMax\", ascending=False).sort_values(\"prices.merchant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBr6ez80Dvrf"
   },
   "source": [
    "### Filter data with Python and Pandas\n",
    "Three useful ways to access particular rows of Pandas DataFrames are by the:\n",
    "- row number; \n",
    "- `index` value; or\n",
    "- column values.\n",
    "Let's take a look at each below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucqy-TDyHdS7"
   },
   "source": [
    "#### Filter by rows\n",
    "The .iloc method can be used to slide the data in the way in which it is currently arranged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "__kHWJsiHcER"
   },
   "outputs": [],
   "source": [
    "# Get the first 10 rows\n",
    "sdf.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kbS6husxHxcj"
   },
   "outputs": [],
   "source": [
    "# Get the 15th row\n",
    "sdf.iloc[15]  # Note that the row object is returned rather than a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rokvx92DFILM"
   },
   "source": [
    "#### Filter by index\n",
    "Each row of a DataFrame includes an `index` value, which acts as a name for each row. \n",
    "\n",
    "This might simply be a meaningless number, but it can be more - it might for example be a date, userID, whatever, allowing for convenient selection of subsets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f62hMRk5FGOc"
   },
   "outputs": [],
   "source": [
    "# Get rows where the index is 10 or smaller\n",
    "sdf.loc[:10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6wrHlx-Haw4"
   },
   "source": [
    "So while that above example might look the same as before, we can do things like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BIAsjQpcHYoQ"
   },
   "outputs": [],
   "source": [
    "# Select rows where the index is smaller than 10, and the vendor is Walmart\n",
    "sdf[sdf[\"prices.merchant\"]==\"Walmart.com\"].loc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzesNptJJ-RC"
   },
   "source": [
    "#### Filter by column data\n",
    "\n",
    "You may have noticed the code `df[df[\"prices.merchant\"]==\"Walmart.com\"]` above when showing how to filter data by the index. \n",
    "\n",
    "This code uses an Boolean array produced by `df[\"prices.merchant\"]==\"Walmart.com\"`, in which each row is marked as TRUE or FALSE, based on whether the row's \"prices.merchant\" column value is \"Walmart.com\".\n",
    "\n",
    "This is an extremely powerful method of data filtering, as any number of logical (and/or) operations can be combined using these Boolean arrays as you will see below.\n",
    "\n",
    "Pay attention to how the query is constructed using brackets, combining logical operations. If you are not sure, I find it helpful to articulate what each clause within one set of brackets is doing, and to consider each conditional (& = AND, | = OR) clause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x7cq_ItfLvMW"
   },
   "outputs": [],
   "source": [
    "# Get the portion of the dataframe where \"prices.merchant\" has \"Walmart.com\" values\n",
    "sdf[sdf[\"prices.merchant\"]==\"Walmart.com\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c2PdkYkrL6aj"
   },
   "outputs": [],
   "source": [
    "# Get the portion of the dataframe where \"prices.merchant\" has \"Walmart.com\" values, \n",
    "# and the prices.amountMax is above 50\n",
    "sdf[(sdf[\"prices.merchant\"]==\"Walmart.com\") & (sdf[\"prices.amountMax\"] > 50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uy0Y0e_aMT2c"
   },
   "outputs": [],
   "source": [
    "# Get the portion of the dataframe where \"prices.merchant\" has \"Walmart.com\" values\n",
    "# and the prices.amountMax is above 60 or less than 10\n",
    "sdf[(sdf[\"prices.merchant\"]==\"Walmart.com\") & ((sdf[\"prices.amountMax\"] > 60) | (sdf[\"prices.amountMax\"] < 10))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7VLJTT3aM56Z"
   },
   "outputs": [],
   "source": [
    "# Get the portion of the dataframe where \"prices.merchant\" is missing values\n",
    "# and by value of prices.amountMax\n",
    "sdf[(sdf[\"prices.merchant\"].isna()) & (sdf[\"prices.amountMax\"] > 120)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LRRiSViTe17D"
   },
   "outputs": [],
   "source": [
    "# Get the portion of the dataframe where \"prices.merchant\" contains string \"com\"\n",
    "# and the prices.amountMax is above 60\n",
    "sdf[(sdf[\"prices.merchant\"].str.contains(\"com\")) & (sdf[\"prices.amountMax\"] > 60)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHhVXE8reuxW"
   },
   "source": [
    "As you can see, Pandas provides flexible and powerful data filtering tools. This just scratches the surface of the large array of ways in which you can filter data in Pandas. \n",
    "\n",
    "To learn more, check out [this tutorial](https://pandas.pydata.org/pandas-docs/dev/getting_started/intro_tutorials/03_subset_data.html) from Pandas, and other methods such as `.query` ([reference](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.query.html)), `.filter` ([reference](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.filter.html)) and how to test for patterns in strings ([reference](https://pandas.pydata.org/pandas-docs/stable/user_guide/text.html#testing-for-strings-that-match-or-contain-a-pattern))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Knh8JoRPi5qN"
   },
   "source": [
    "# Data type conversions\n",
    "\n",
    "Now, let's take a look at how to convert data types within Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ualcl4wE6U2"
   },
   "source": [
    "### Data types - Simple conversion \n",
    "\n",
    "To convert one data type to another in a DataFrame, the `.astype` method can be used ([read more](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html)). Take a look below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D1w3CCqYNt63"
   },
   "outputs": [],
   "source": [
    "# Floating point to String\n",
    "df[\"prices.amountMax\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_gMB3281Rntz"
   },
   "outputs": [],
   "source": [
    "# Floating point to Integer (rounds down)\n",
    "df[\"prices.amountMax\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zd27taNaEtge"
   },
   "outputs": [],
   "source": [
    "# Boolean to Binary / Integer\n",
    "df[\"prices.isSale\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U79x2SyqInQ6"
   },
   "source": [
    "### Data types - converting dates\n",
    "\n",
    "Without manual intervention, dates and/or times are usually loaded as strings. However, they are best handled in a native datetime format as it allows date/time specific operations.\n",
    "\n",
    "Take a look at a few examples below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lyN_0BAoSuRg"
   },
   "source": [
    "What happens when we manipulate the data as-is, without converting it to a datetime object?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5LphmJGwShCx"
   },
   "outputs": [],
   "source": [
    "# Grab the year data - first four characters of the \"dateAdded\" column\n",
    "df[\"dateAddedYr\"] = df[\"dateAdded\"].str[:4]\n",
    "print(df[\"dateAddedYr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BTbEmU2ETnnT"
   },
   "outputs": [],
   "source": [
    "# What happens if we operate on the year column?\n",
    "df[\"dateAddedYr\"] * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L3ql_ENATfU6"
   },
   "outputs": [],
   "source": [
    "# So let's convert the data to integers\n",
    "df[\"dateAddedYr\"] = df[\"dateAddedYr\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-mxoF0oruYD"
   },
   "source": [
    "But, many of our operations are easier if the column is converted to datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f-k2mhdUT3QX"
   },
   "outputs": [],
   "source": [
    "# Actually, \"2015-05-04T12:13:08Z\" is a standard datetime format. This can be simply converted to datetime objects.\n",
    "df[\"dateAdded\"] = pd.to_datetime(df[\"dateAdded\"])\n",
    "df[\"dateAdded\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2W_v0OjmUfrb"
   },
   "outputs": [],
   "source": [
    "# Once the column has been converted to a datetime objects, their properties can be accessed with various methods under the `.dt` set\n",
    "print(df[\"dateAdded\"].dt.year)  # Year\n",
    "print(df[\"dateAdded\"].dt.timetz)  # Timezone\n",
    "print(df[\"dateAdded\"].dt.dayofweek)  # Day (monday=0, sunday=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pDdtGx6XNLOE"
   },
   "outputs": [],
   "source": [
    "# This can be now used to easily filter our data\n",
    "# let's say we want to see all data added in 2017 or later, and on Saturday/Sunday.\n",
    "df[(df[\"dateAdded\"].dt.year >= 2017) & (df[\"dateAdded\"].dt.dayofweek >= 6)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qyh1eHCzs6Nx"
   },
   "source": [
    "If you will be working with date/time data, we recommend reading [this tutorial](https://pandas.pydata.org/docs/getting_started/intro_tutorials/09_timeseries.html), and [this reference guide](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AcademyXi_DA_Module_3_data_manip_workshop.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}